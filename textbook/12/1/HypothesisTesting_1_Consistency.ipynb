{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983992f",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15231c07",
   "metadata": {},
   "source": [
    "# Evaluate the consistency between data and a model\n",
    "\n",
    "To understand how consistency of a dataset with a model can be evaluated, we start with a simple example. We use the last model described in the previous section that states that 100 data points are generated independently from a uniform distribution: $U(1,5)$.\n",
    "\n",
    "The next cell shows the creation of a dataset saved in an array of length 100 called `dataset`; for the moment, ignore the way the data was generated (it was purposefully skewed!) and evaluate the distribution of the data from the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65467556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "dataset=np.concatenate((np.random.uniform(1,2,size=20),np.random.uniform(1,5,size=80)))\n",
    "plt.hist(dataset,bins=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951b1f8",
   "metadata": {},
   "source": [
    "Is it plausible that the data shown in the above histogram was generated from the $U(1,5)$ distribution?\n",
    "\n",
    "The histogram is not entirely conclusive. We can simulate datasets of the same sample size (100) from the $U(1,5)$ distribution, but it is unclear how we can compare histograms. \n",
    "\n",
    "It is easier to evaluate a numerical characteristic of the data, such as the median, instead of looking at the full dataset. Below we calculate the median of the values in our data and we also generate 1,000 datasets from our model for which we obtain their medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6640395",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd51916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array where we will save the simulated medians\n",
    "med_dist=np.array([])\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(5678)\n",
    "\n",
    "# generate 1000 medians \n",
    "for i in np.arange(1000):\n",
    "    med_dist=np.append(med_dist,np.median(np.random.uniform(1,5,size=100)))\n",
    "\n",
    "plt.hist(med_dist,bins=20)\n",
    "plt.scatter(np.median(dataset), -2, color='red', s=30)\n",
    "plt.title('1000 simulated datasets')\n",
    "plt.xlabel(\"Medians\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa676432",
   "metadata": {},
   "source": [
    "The above histogram shows the 1,000 medians we generated together with the median value we had in our dataset (the red dot). The location of the red dot in this distribution is an indication of how consistent the data are with the model. One indicator of consistency is how likely it is to obtain the observed median or something more extreme from our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(med_dist<=np.median(dataset))/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce8127",
   "metadata": {},
   "source": [
    "We see above that 2.3% of datasets obtained from our model have a median that is at least as small as the observed one. We can use this information to get insight into our question. A schematic of the process we use to determine consistency is below and has the following steps: \n",
    "- select a statistic, S, that will be used to check consistency (we used the median in the above example); \n",
    "- use the model to generate/simulate datasets; \n",
    "- compare the observed value for the statistic, S, with the distribution obtained for S from the datasets generated from the model (as we did in the histogram above). \n",
    "\n",
    "<img align=\"center\" src=\"./dgm2.png\" width=\"400\"/>\n",
    "\n",
    "The question we pose is: *How likely is to obtain a value for S as extreme as what we have in  our data from the distribution we generated?* In the above example, the tail probability, 0.023, was a possible answer to this question.\n",
    "\n",
    "**Note:** The choice of statistics is an important consideration as results and conclusions could differ from statistic to statistic (for an example of this, see the next section [Chapter 12.3](../../13/3/HypothesisTesting_3_TwoSample.ipynb)). \n",
    "\n",
    "We now turn to a real dataset from the CDC[^***] that contains the number of births by state, race, age of mother and infant gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1dbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data from CDC\n",
    "natality2016=pd.read_csv(\"../../data/Natality2016.csv\")\n",
    "natality2016.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceec860-436a-4d87-af74-f761b22a1114",
   "metadata": {},
   "source": [
    "First, let's evaluate the number of `Births` by `Gender.Code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd0072",
   "metadata": {},
   "outputs": [],
   "source": [
    "natality2016[['Gender.Code','Births']].groupby('Gender.Code').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628685f",
   "metadata": {},
   "source": [
    "We can see from the above summary that, in 2016, more boys were born in the United States than girls. Is this consistent with the model where the probability of having a boy is 0.5? \n",
    "\n",
    "We can answer this immediately by generating data from that model. \n",
    "\n",
    "We use the binomial distribution with n = 1,925,598 + 2,016,003 = 3,941,601 to investigate this question. \n",
    "\n",
    "The histogram below shows that having more than 2 million boys is inconsistent with our binomial model, suggesting that the probability of having a boy is not equal to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2dc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot results from random samples from a binomial distribution \n",
    "# n is the number of trials (same size as our population)\n",
    "# p is the probability of being a boy\n",
    "# size is the number of simulated datasets we will create\n",
    "plt.hist(np.random.binomial(n=1925598+2016003, p= 0.5, size=10000))\n",
    "plt.title('10,000 simulated datasets')\n",
    "plt.xlabel(\"Number of boys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee442a32",
   "metadata": {},
   "source": [
    "It turns out that for many countries, the probability of having a boy is 0.512 which corresponds to 105 boys being born for every 100 girls, leading to a ratio of 1.05 which is known as the secondary sex ratio (SSR). You can read more information on [sex ratio here](https://en.wikipedia.org/wiki/Sex_ratio)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a7ef0f-d595-4817-afa0-e2c32331663f",
   "metadata": {},
   "source": [
    "[^***]: Centers for Disease Control and Prevention. Natality (2016). https://wonder.cdc.gov/natality.html. Accessed 26 Sept. 2025."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
