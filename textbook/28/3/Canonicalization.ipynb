{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010825f7-2076-4e2d-aecb-a4ecd87ab0d6",
   "metadata": {},
   "source": [
    "# Canonicalization\n",
    "In several areas, there are explicit rules to standardize the representation of data.  This procedure, called canonicalization or normalization, removes differences that are not important and permits tests for exact matches to succeed even when the details of the representation have been changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c4cd4-16b2-4edc-9ba4-b45f58e8e28c",
   "metadata": {},
   "source": [
    "## Name normalization\n",
    "\n",
    "Consider a list of names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0823cc-dd4e-4fb7-b910-961c039c3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ \"THOMPSON, EMILY\",\n",
    "          \"THOMPSON,EMILY\",\n",
    "          \"THOMPSON,   EMILY \",\n",
    "          \"Thompson, Emily \",\n",
    "          \"Thompson, Emily A.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1fc7a0-5605-4ea3-88c9-8e0d8d467f57",
   "metadata": {},
   "source": [
    "We cannot tell how many Emily Thompsons are in this database, but the number of spaces is usually not relevant.\n",
    "\n",
    "The string methods `.upper()` and `.lower()` and `.strip()` are potentially useful to this end.  \n",
    "\n",
    "If we wanted to make all of these the same, we could write a function to clean up capitalization and spacing differences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf23cb77-02ed-4b95-bdd9-508db7aeb6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THOMPSON, EMILY\n",
      "THOMPSON, EMILY\n",
      "THOMPSON, EMILY\n",
      "THOMPSON, EMILY\n",
      "THOMPSON, EMILY A.\n"
     ]
    }
   ],
   "source": [
    "def clean(s):\n",
    "    fields = s.upper().strip().split(',')\n",
    "    return(fields[0].strip() + \", \" + fields[1].strip())\n",
    "\n",
    "for name in names:\n",
    "    print( clean(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cb60c-b995-44f4-9d1a-6921882a1dea",
   "metadata": {},
   "source": [
    "Now a \"messy\" list of five different Emilies is now a list of only two (possibly) different names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabc55a-5f96-4ddf-a680-1e6678b71e2c",
   "metadata": {},
   "source": [
    "## URI normalization \n",
    "\n",
    "As an example of how engineers use normalization, we can consider Uniform Resource Identifier (URI) normalization.  URIs are addresses that provide the location of digital resources; URLs are a subset of the standard specifying URIs.\n",
    "\n",
    "URI normalization is described in the standards document [RFC 3986](https://datatracker.ietf.org/doc/html/rfc3986).  The standard contains a list of algorithmic modifications to a URI aimed to allow the sameness of a URI to be identified.\n",
    "\n",
    "This set of rules permits a webserver to store only one copy of some page even if browsers ask for it with dozens of synonymous addresses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fe7cb-c1b5-470b-b98e-6c506fdb9b0e",
   "metadata": {},
   "source": [
    "Duplicate slashes should be removed:\n",
    "    \n",
    "    http://example.com/foo//bar.html → http://example.com/foo/bar.html\n",
    "\n",
    "Relative directory navigation symbols should be interpreted and removed:\n",
    "\n",
    "    http://example.com/foo/../bar.html → http://example.com/bar.html\n",
    "    \n",
    "Certain ascii characters do not require percent encoding in URI strings, and should be decoded:\n",
    "\n",
    "    http://example.com/%7Efoo → http://example.com/~foo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe42e6-d1db-42da-9212-73ecb7288ed2",
   "metadata": {},
   "source": [
    "Although the standard allows multiple, synonymous addresses to be constructed, it would waste resources if it were not possible to boil disparate addresses down to a canonical form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46425e7e-f90e-491e-9e68-09083d0a92c7",
   "metadata": {},
   "source": [
    "## Cleaning up our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72bcea-adfc-4762-abc1-9bb1b3dec7db",
   "metadata": {},
   "source": [
    "Differences in the data representation that are superficial and unimportant can sometimes stand in the way of analysis.  As a first step, we should explore our data to find what kinds of extraneous differences in encodings are present, and then make a copy of the data that has been \"cleaned\" of the differences that we were able to identify.\n",
    "\n",
    "The practice of collecting unusual (or pathological) examples of data can help you make your code work better.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
